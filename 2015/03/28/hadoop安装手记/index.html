<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="hadoop,spark," />





  <link rel="alternate" href="/atom.xml" title="奔跑的兔子" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="写在前面：本文中的安装环境是Mac，仅仅是为了学习了解，所以以快速把系统跑起来为目的，参数尽可能用默认配置。另外本文写作时间跨度较长，中间有相当时间的间隔，所以会出现不同版本的hadoop。
设置SSH单节点运行hadoop需要本机ssh连通。生成key的过程没什么特殊的：
ssh-keygen -t rsacat .ssh/id_rsa.pub &amp;gt;&amp;gt;.ssh/authorized_k">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop安装手记">
<meta property="og:url" content="http://sunyi514.github.io/2015/03/28/hadoop安装手记/index.html">
<meta property="og:site_name" content="奔跑的兔子">
<meta property="og:description" content="写在前面：本文中的安装环境是Mac，仅仅是为了学习了解，所以以快速把系统跑起来为目的，参数尽可能用默认配置。另外本文写作时间跨度较长，中间有相当时间的间隔，所以会出现不同版本的hadoop。
设置SSH单节点运行hadoop需要本机ssh连通。生成key的过程没什么特殊的：
ssh-keygen -t rsacat .ssh/id_rsa.pub &amp;gt;&amp;gt;.ssh/authorized_k">
<meta property="og:image" content="http://7xltg5.com1.z0.glb.clouddn.com/yarn_webui.jpg">
<meta property="og:image" content="http://7xltg5.com1.z0.glb.clouddn.com/mr-his.jpg">
<meta property="og:image" content="http://7xltg5.com1.z0.glb.clouddn.com/spark-his.jpg">
<meta property="og:image" content="http://7xltg5.com1.z0.glb.clouddn.com/hadoop-timeline.jpg">
<meta property="og:updated_time" content="2016-07-09T07:50:00.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hadoop安装手记">
<meta name="twitter:description" content="写在前面：本文中的安装环境是Mac，仅仅是为了学习了解，所以以快速把系统跑起来为目的，参数尽可能用默认配置。另外本文写作时间跨度较长，中间有相当时间的间隔，所以会出现不同版本的hadoop。
设置SSH单节点运行hadoop需要本机ssh连通。生成key的过程没什么特殊的：
ssh-keygen -t rsacat .ssh/id_rsa.pub &amp;gt;&amp;gt;.ssh/authorized_k">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://sunyi514.github.io/2015/03/28/hadoop安装手记/"/>





  <title> Hadoop安装手记 | 奔跑的兔子 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-60954885-1', 'auto');
  ga('send', 'pageview');
</script>









  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">奔跑的兔子</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://sunyi514.github.io/2015/03/28/hadoop安装手记/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="奔跑的兔子">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="http://7xltg5.com1.z0.glb.clouddn.com/author.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="奔跑的兔子">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="奔跑的兔子" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                Hadoop安装手记
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              <time title="Дата создания записи" itemprop="dateCreated datePublished" datetime="2015-03-28T17:28:11+08:00">
                2015-03-28
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
              <span class="post-meta-divider">|</span>
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/data-system/" itemprop="url" rel="index">
                    <span itemprop="name">data system</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <a href="/2015/03/28/hadoop安装手记/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2015/03/28/hadoop安装手记/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>写在前面：本文中的安装环境是Mac，仅仅是为了学习了解，所以以快速把系统跑起来为目的，参数尽可能用默认配置。另外本文写作时间跨度较长，中间有相当时间的间隔，所以会出现不同版本的hadoop。</p>
<h1 id="设置SSH">设置SSH</h1><p>单节点运行hadoop需要本机ssh连通。生成key的过程没什么特殊的：</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br><span class="line">cat .ssh/id_rsa.pub <span class="prompt">&gt;&gt;</span>.ssh/authorized_keys</span><br></pre></td></tr></table></figure>
<p>然后需要开启ssh服务，具体设置在“系统偏好设置-&gt;共享-&gt;远程登录”，把这个勾上即可。</p>
<p>如果发现配置之后不生效，多半是权限问题，可以检查一下<code>authorized_keys</code>是不是权限是600，另外家目录（比如对我的环境来讲就是<code>/Users/sunyi</code>）的权限是不是755。</p>
<h1 id="环境变量">环境变量</h1><p>首先保证安装了java7，然后到官网下载hadoop，解压（方便起见就不新开用户了，直接放到当前用户目录下）。接下来就需要做些环境变量设置。</p>
<p>首先在/etc/bashrc文件中增加如下设置：</p>
<figure class="highlight xquery"><table><tr><td class="code"><pre><span class="line">export HADOOP_HOME=/Users/sunyi/hadoop-<span class="number">2.3</span>.<span class="number">0</span></span><br><span class="line">export PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP</span>_HOME/bin:<span class="variable">$HADOOP</span>_HOME/sbin</span><br></pre></td></tr></table></figure>
<p>这样就能直接访问hadoop shell了，可以用如下命令做个测试:</p>
<figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line">hadoop <span class="property">version</span></span><br></pre></td></tr></table></figure>
<p>然后在<code>hadoop-env.sh</code>/<code>mapred-env.sh</code>/<code>yarn-env.sh</code>里面设一下java环境变量：</p>
<figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line">export JAV<span class="built_in">A_HOME</span>=<span class="escape">`/</span>usr/libexec/jav<span class="built_in">a_home</span>`</span><br></pre></td></tr></table></figure>
<h1 id="Hadoop配置项">Hadoop配置项</h1><p>这里就直接罗列一下配置项了。</p>
<p><strong>core-site.xml</strong></p>
<figure class="highlight pf"><table><tr><td class="code"><pre><span class="line"><span class="variable">&lt;configuration&gt;</span>  </span><br><span class="line">   <span class="variable">&lt;property&gt;</span>  </span><br><span class="line">     <span class="variable">&lt;name&gt;</span>fs.<span class="keyword">default</span>.name<span class="variable">&lt;/name&gt;</span>  </span><br><span class="line">       <span class="variable">&lt;value&gt;</span>hdfs://localhost:<span class="number">9000</span><span class="variable">&lt;/value&gt;</span>  </span><br><span class="line">   <span class="variable">&lt;/property&gt;</span>  </span><br><span class="line"> <span class="variable">&lt;/configuration&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>hdfs-site.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">configuration</span>&gt;</span>  </span><br><span class="line">   <span class="tag">&lt;<span class="title">property</span>&gt;</span>  </span><br><span class="line">     <span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="title">name</span>&gt;</span>  </span><br><span class="line">     <span class="tag">&lt;<span class="title">value</span>&gt;</span>1<span class="tag">&lt;/<span class="title">value</span>&gt;</span>  </span><br><span class="line">   <span class="tag">&lt;/<span class="title">property</span>&gt;</span>  </span><br><span class="line">   <span class="tag">&lt;<span class="title">property</span>&gt;</span>  </span><br><span class="line">     <span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="title">name</span>&gt;</span>  </span><br><span class="line">     <span class="tag">&lt;<span class="title">value</span>&gt;</span>file:/Users/sunyi/hdfs/namenode<span class="tag">&lt;/<span class="title">value</span>&gt;</span>  </span><br><span class="line">   <span class="tag">&lt;/<span class="title">property</span>&gt;</span>  </span><br><span class="line">   <span class="tag">&lt;<span class="title">property</span>&gt;</span>  </span><br><span class="line">     <span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="title">name</span>&gt;</span>  </span><br><span class="line">     <span class="tag">&lt;<span class="title">value</span>&gt;</span>file:/Users/sunyi/hdfs/datanode<span class="tag">&lt;/<span class="title">value</span>&gt;</span>  </span><br><span class="line">   <span class="tag">&lt;/<span class="title">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="title">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>mapred-site.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="title">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="title">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>yarn-site.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">configuration</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="title">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="title">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="title">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="title">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce_shuffle.class<span class="tag">&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="title">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="tag">&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">property</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="title">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>其中<code>hdfs-site.xml</code>注意提前建好相应的目录，<code>yarn-site.xml</code>配置时注意不要用以前2.0版本时的配置，也就是不要用mapreduce.shuffle或者mapreduce-shuffle这样的写法，如果这样写的话，会出现启动后nodemanager启动失败，还有job运行失败等现象。</p>
<h1 id="启动Hadoop">启动Hadoop</h1><p>首先格式化hdfs，然后依次启动hdfs和yarn。</p>
<figure class="highlight dos"><table><tr><td class="code"><pre><span class="line">hadoop namenode -<span class="built_in">format</span></span><br><span class="line">./sbin/<span class="built_in">start</span>-dfs.sh</span><br><span class="line">./sbin/<span class="built_in">start</span>-yarn.sh</span><br></pre></td></tr></table></figure>
<p>然后可以用jps确认下进程全部顺利启动，会看到下面这些进程，有问题就检查下log。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="number">8431</span> ResourceManager</span><br><span class="line"><span class="number">8525</span> NodeManager</span><br><span class="line"><span class="number">9095</span> Jps</span><br><span class="line"><span class="number">8313</span> SecondaryNameNode</span><br><span class="line"><span class="number">8207</span> DataNode</span><br><span class="line"><span class="number">8120</span> NameNode</span><br></pre></td></tr></table></figure>
<p>成功启动后，就可以用浏览器看看<code>localhost:50070</code>和<code>localhost:8088</code>的hdfs和yarn管理页面了。</p>
<h1 id="Job测试">Job测试</h1><p>找一个文本，传到hdfs上面，然后运行一下hadoop自带的wordcount job：</p>
<figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*<span class="class">.jar</span> wordcount <span class="tag">input</span><span class="class">.txt</span> out</span><br></pre></td></tr></table></figure>
<p>或者运行一个不依赖hdfs数据的job也可以，比如pi计算：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar pi <span class="number">10</span> <span class="number">100000</span></span><br></pre></td></tr></table></figure>
<p>运行成功后yarn管理页如下图：<br> <img src="http://7xltg5.com1.z0.glb.clouddn.com/yarn_webui.jpg" alt="yarn_webui"></p>
<p>在运行job或者是其他任何hadoop命令时，都会碰到下面两个warning：</p>
<ul>
<li><p><strong>Unable to load realm info from SCDynamicStore</strong>：这个是mac下特有的安全方面的问题警告，可以通过在<code>hadoop-env.sh</code>中增加如下配置消除。</p>
<figure class="highlight 1c"><table><tr><td class="code"><pre><span class="line">HADOOP_OPTS=<span class="string">"$&#123;HADOOP_OPTS&#125; -Djava.security.krb5.realm= </span></span><br><span class="line">-Djava.security.krb5.kdc= -Djava.security.krb5.conf=/dev/null<span class="string">"</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Unable to load native-hadoop library for your platform</strong>：这个警告的原因是hadoop自带的native lib是32位的，在64位的系统上自然是版本不一致。如果需要解决这个问题，需要自己编译一下，替换掉原来的lib即可，由于这里仅仅是学习用，就不做这件事情了。</p>
</li>
</ul>
<h1 id="MR_History_Server">MR History Server</h1><p>为了开启MR的History Server，首先需要在<code>yarn-site.xml</code>里面配置log aggregation，并且指定log目录打开地址（如果不配置参数的话其实也能启动，但是在主界面上是打不开log内容的）：</p>
<figure class="highlight pf"><table><tr><td class="code"><pre><span class="line"><span class="variable">&lt;property&gt;</span></span><br><span class="line">    <span class="variable">&lt;name&gt;</span>yarn.<span class="keyword">log</span>.server.url<span class="variable">&lt;/name&gt;</span></span><br><span class="line">    <span class="variable">&lt;value&gt;</span>http://localhost:<span class="number">19888</span>/jobhistory/logs<span class="variable">&lt;/value&gt;</span></span><br><span class="line"><span class="variable">&lt;/property&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">&lt;property&gt;</span></span><br><span class="line">    <span class="variable">&lt;name&gt;</span>yarn.log-aggregation-enable<span class="variable">&lt;/name&gt;</span></span><br><span class="line">    <span class="variable">&lt;value&gt;</span>true<span class="variable">&lt;/value&gt;</span></span><br><span class="line"><span class="variable">&lt;/property&gt;</span></span><br></pre></td></tr></table></figure>
<p>然后，运行如下命令即可启动：</p>
<figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">./sbin/mr-jobhistory-daemon<span class="class">.sh</span> start historyserver</span><br></pre></td></tr></table></figure>
<p>现在，已完成的任务的Tracking URL将从App Master“移交给”History Server。另外在jobhistory的界面<code>localhost:19888</code>上也可以看到所有已经完成的任务：</p>
<p> <img src="http://7xltg5.com1.z0.glb.clouddn.com/mr-his.jpg" alt="mr-his"></p>
<p>另外，如果想从命令行来看日志，可以用yarn logs命令，比如典型的查看am的log，就是：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">yarn logs -applicationId <span class="tag">&lt;<span class="title">APP_ID</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h1 id="Spark_on_Yarn">Spark on Yarn</h1><p>Spark on Yarn的基本安装很简单。首先确保scala环境已经安装，这里就不再赘述了。下载spark后（这里用的是<code>spark-1.3-hadoop-2.4</code>），在<code>conf/spark-env.sh</code>里面设置hadoop conf目录即可：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">export</span> HADOOP_CONF_DIR=/Users/sunyi/develop/hadoop-<span class="number">2.5</span><span class="number">.0</span>-cdh5<span class="number">.3</span><span class="number">.0</span>/etc/hadoop</span><br></pre></td></tr></table></figure>
<p>然后就可以开始运行spark job，不需要像独立部署时启动master/worker之类的了：</p>
<figure class="highlight crystal"><table><tr><td class="code"><pre><span class="line">./bin/spark-submit --<span class="class"><span class="keyword">class</span> <span class="title">org</span>.<span class="title">apache</span>.<span class="title">spark</span>.<span class="title">examples</span>.<span class="title">SparkPi</span> \</span></span><br><span class="line">    --master yarn-cluster \</span><br><span class="line">    --num-executors <span class="number">4</span> \</span><br><span class="line">    --driver-memory <span class="number">1</span>g \</span><br><span class="line">    --executor-memory <span class="number">1</span>g \</span><br><span class="line">    --executor-cores <span class="number">1</span> \</span><br><span class="line">    <span class="class"><span class="keyword">lib</span>/<span class="title">spark</span>-<span class="title">examples</span>-*.<span class="title">jar</span> \</span></span><br><span class="line">    <span class="number">100</span></span><br></pre></td></tr></table></figure>
<p>可以看到只需要指定master为yarn-cluster，并且给出一些运行参数即可。Spark的运行依赖spark-assembly和应用程序spark-examples会从本地上传。当然，可以用SPARK_JAR变量指定spark-assembly的位置，并且上传spark-assembly到hdfs：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">export</span> SPARK_JAR=hdfs:<span class="comment">//localhost:9000/spark-assembly-1.3.0-hadoop2.4.0.jar</span></span><br></pre></td></tr></table></figure>
<h1 id="Spark_History_Server">Spark History Server</h1><p>Spark同样有自己的History Server。配置方法是在conf目录下编辑<code>spark-default.conf</code>，加入如下3行：</p>
<figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">spark<span class="class">.eventLog</span><span class="class">.enabled</span> 		 true</span><br><span class="line">spark<span class="class">.yarn</span><span class="class">.historyServer</span><span class="class">.address</span> localhost:<span class="number">18080</span></span><br><span class="line">spark<span class="class">.eventLog</span><span class="class">.dir</span>               hdfs:<span class="comment">//localhost:9000/spark-log</span></span><br></pre></td></tr></table></figure>
<p>这三行分别指定了开启日志记录，ui地址，以及日志目录（要提前建好目录）。然后就可以启动了：</p>
<figure class="highlight vim"><table><tr><td class="code"><pre><span class="line">./sbin/start-<span class="keyword">history</span>-server.<span class="keyword">sh</span>  hdf<span class="variable">s:</span>//localhos<span class="variable">t:9000</span>/spark-<span class="built_in">log</span></span><br></pre></td></tr></table></figure>
<p>这样，刚才我们的spark pi任务在运行结束后就可以在<code>localhost:18080</code>界面上看到了：</p>
<p> <img src="http://7xltg5.com1.z0.glb.clouddn.com/spark-his.jpg" alt="spark-his"></p>
<h1 id="Hadoop_Timeline_Server">Hadoop Timeline Server</h1><p>Timeline Server是hadoop2.4新引入的一个功能。由于hadoop2开始支持各种计算框架，而目前各个框架自己都提供独立的history server机制，所以Timeline Server的主要意义在于将各个框架自己提供的history server统一集成到一个history server中，方便用户统一查询已完成的所有任务，主要功能分为两块：</p>
<ul>
<li>提供已完成任务的通用信息，包括任务名，队列等等，这个跟yarn主界面看到的类似。</li>
<li>集中收集各个框架提供的任务信息，比如mapreduce的map数，reduce数，counter等等，以便进行统一查询。</li>
</ul>
<p>其中第二个功能目前还不太完善，只提供API方式获取数据，这里就配置一下第一个功能。配置方法就是在<code>yarn-site.xml</code>中添加如下配置开启：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="title">name</span>&gt;</span>yarn.timeline-service.generic-application-history.enabled<span class="tag">&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="title">value</span>&gt;</span>true<span class="tag">&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="title">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="title">name</span>&gt;</span>yarn.timeline-service.generic-application-history.store-class<span class="tag">&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="title">value</span>&gt;</span>org.apache.hadoop.yarn.server.applicationhistoryservice.</span><br><span class="line">         FileSystemApplicationHistoryStore<span class="tag">&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>然后启动Timeline Server：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="title">yarn</span> historyserver</span><br></pre></td></tr></table></figure>
<p>这样就可以打开默认界面<code>localhost:8188</code>，所有之前运行的mr和spark任务都已经可以在界面上看到：</p>
<p> <img src="http://7xltg5.com1.z0.glb.clouddn.com/hadoop-timeline.jpg" alt="hadoop-timeline"></p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/hadoop/" rel="tag"># hadoop</a>
          
            <a href="/tags/spark/" rel="tag"># spark</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2014/11/15/盘点sql-on-hadoop中用到的主要技术/" rel="next" title="盘点SQL on Hadoop中用到的主要技术">
                <i class="fa fa-chevron-left"></i> 盘点SQL on Hadoop中用到的主要技术
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2015/08/21/elements-of-scale阅读笔记/" rel="prev" title="Elements of Scale阅读笔记">
                Elements of Scale阅读笔记 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="2015/03/28/hadoop安装手记/"
           data-title="Hadoop安装手记" data-url="http://sunyi514.github.io/2015/03/28/hadoop安装手记/">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="http://7xltg5.com1.z0.glb.clouddn.com/author.jpg"
               alt="奔跑的兔子" />
          <p class="site-author-name" itemprop="name">奔跑的兔子</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">7</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">2</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">11</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/u/1731546452" target="_blank" title="weibo">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  weibo
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#设置SSH"><span class="nav-number">1.</span> <span class="nav-text">设置SSH</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#环境变量"><span class="nav-number">2.</span> <span class="nav-text">环境变量</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Hadoop配置项"><span class="nav-number">3.</span> <span class="nav-text">Hadoop配置项</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#启动Hadoop"><span class="nav-number">4.</span> <span class="nav-text">启动Hadoop</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Job测试"><span class="nav-number">5.</span> <span class="nav-text">Job测试</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MR_History_Server"><span class="nav-number">6.</span> <span class="nav-text">MR History Server</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Spark_on_Yarn"><span class="nav-number">7.</span> <span class="nav-text">Spark on Yarn</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Spark_History_Server"><span class="nav-number">8.</span> <span class="nav-text">Spark History Server</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Hadoop_Timeline_Server"><span class="nav-number">9.</span> <span class="nav-text">Hadoop Timeline Server</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2013 - 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">奔跑的兔子</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"sunyi514"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  








  
  

  

  

  

  



<!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"TeX":{"equationNumbers":{"autoNumber":["AMS"],"useLabelIds":true}},"SVG":{"linebreaks":{"automatic":true}},"HTML-CSS":{"preferredFont":"TeX","availableFonts":["STIX","TeX"],"linebreaks":{"automatic:true":null}},"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"processEscapes":true,"skipTags":["script","noscript","style","textarea","pre","code"]},"messageStyle":"none"});
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
</body>
</html>
