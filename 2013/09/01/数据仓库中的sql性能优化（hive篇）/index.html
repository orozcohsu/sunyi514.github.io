<!doctype html>
<html class="theme-next use-motion theme-next-mist">
<head>
  

<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />








  <link rel="stylesheet" type="text/css" href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5"/>




<link rel="stylesheet" type="text/css" href="/css/main.css?v=0.4.5.1"/>




  <meta name="keywords" content="hive,sql on hadoop," />





  <link rel="shorticon icon" type="image/x-icon" href="/favicon.ico?v=0.4.5.1" />


<meta name="description" content="一个Hive查询生成多个map reduce job，一个map reduce job又有map，reduce，spill，shuffle，sort等多个阶段，所以针对hive查询的优化可以大致分为针对MR中单个步骤的优化（其中又会有细分），针对MR全局的优化，和针对整个查询（多MR job）的优化，下文会分别阐述。

在开始之前，先把MR的流程图帖出来（摘自Hadoop权威指南），方便后面对照。">
<meta property="og:type" content="article">
<meta property="og:title" content="数据仓库中的SQL性能优化（Hive篇）">
<meta property="og:url" content="http://sunyi514.github.io/2013/09/01/数据仓库中的sql性能优化（hive篇）/index.html">
<meta property="og:site_name" content="奔跑的兔子">
<meta property="og:description" content="一个Hive查询生成多个map reduce job，一个map reduce job又有map，reduce，spill，shuffle，sort等多个阶段，所以针对hive查询的优化可以大致分为针对MR中单个步骤的优化（其中又会有细分），针对MR全局的优化，和针对整个查询（多MR job）的优化，下文会分别阐述。

在开始之前，先把MR的流程图帖出来（摘自Hadoop权威指南），方便后面对照。">
<meta property="og:image" content="http://7xltg5.com1.z0.glb.clouddn.com/hive_opt_section.jpg">
<meta property="og:image" content="http://7xltg5.com1.z0.glb.clouddn.com/mr.jpg">
<meta property="og:image" content="http://7xltg5.com1.z0.glb.clouddn.com/mr_skew.jpg">
<meta property="og:image" content="http://7xltg5.com1.z0.glb.clouddn.com/skew_join.jpg">
<meta property="og:updated_time" content="2015-12-19T10:55:16.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="数据仓库中的SQL性能优化（Hive篇）">
<meta name="twitter:description" content="一个Hive查询生成多个map reduce job，一个map reduce job又有map，reduce，spill，shuffle，sort等多个阶段，所以针对hive查询的优化可以大致分为针对MR中单个步骤的优化（其中又会有细分），针对MR全局的优化，和针对整个查询（多MR job）的优化，下文会分别阐述。

在开始之前，先把MR的流程图帖出来（摘自Hadoop权威指南），方便后面对照。">


<script type="text/javascript" id="hexo.configuration">
  var CONFIG = {
    scheme: 'Mist',
    sidebar: 'post'
  };
</script>

  <title> 数据仓库中的SQL性能优化（Hive篇） | 奔跑的兔子 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  <!--[if lte IE 8]>
  <div style=' clear: both; height: 59px; padding:0 0 0 15px; position: relative;margin:0 auto;'>
    <a href="http://windows.microsoft.com/en-US/internet-explorer/products/ie/home?ocid=ie6_countdown_bannercode">
      <img src="http://7u2nvr.com1.z0.glb.clouddn.com/picouterie.jpg" border="0" height="42" width="820"
           alt="You are using an outdated browser. For a faster, safer browsing experience, upgrade for free today or use other browser ,like chrome firefox safari."
           style='margin-left:auto;margin-right:auto;display: block;'/>
    </a>
  </div>
<![endif]-->
  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-60954885-1', 'auto');
  ga('send', 'pageview');
</script>




  <div class="container one-column page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><h1 class="site-meta">
  <span class="logo-line-before"><i></i></span>
  <a href="/" class="brand" rel="start">
      <span class="logo">
        <i class="icon-next-logo"></i>
      </span>
      <span class="site-title">奔跑的兔子</span>
  </a>
  <span class="logo-line-after"><i></i></span>
</h1>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu ">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            <i class="menu-item-icon icon-next-home"></i> <br />
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            <i class="menu-item-icon icon-next-categories"></i> <br />
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            <i class="menu-item-icon icon-next-about"></i> <br />
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            <i class="menu-item-icon icon-next-archives"></i> <br />
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            <i class="menu-item-icon icon-next-tags"></i> <br />
            标签
          </a>
        </li>
      

      
      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div id="content" class="content"> 

  <div id="posts" class="posts-expand">
    

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              数据仓库中的SQL性能优化（Hive篇）
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2013-09-01T18:01:52+08:00" content="2013-09-01">
            2013-09-01
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/data-system/" itemprop="url" rel="index">
                  <span itemprop="name">data system</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2013/09/01/数据仓库中的sql性能优化（hive篇）/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2013/09/01/数据仓库中的sql性能优化（hive篇）/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        <span itemprop="articleBody"><p>一个Hive查询生成多个map reduce job，一个map reduce job又有map，reduce，spill，shuffle，sort等多个阶段，所以针对hive查询的优化可以大致分为针对MR中单个步骤的优化（其中又会有细分），针对MR全局的优化，和针对整个查询（多MR job）的优化，下文会分别阐述。</p>
<p><img src="http://7xltg5.com1.z0.glb.clouddn.com/hive_opt_section.jpg" alt="hive_opt_section"></p>
<p>在开始之前，先把MR的流程图帖出来（摘自Hadoop权威指南），方便后面对照。另外要说明的是，这个优化只是针对Hive 0.9版本，而不是后来Hortonwork发起Stinger项目之后的版本。相对应的Hadoop版本是1.x而非2.x。</p>
<p><img src="http://7xltg5.com1.z0.glb.clouddn.com/mr.jpg" alt="mr process"></p>
<h1 id="Map阶段的优化(map_phase)">Map阶段的优化(map phase)</h1><p>Map阶段的优化，主要是确定合适的map数。那么首先要了解map数的计算公式：</p>
<figure class="highlight processing"><table><tr><td class="code"><pre><span class="line">num_map_tasks = <span class="built_in">max</span>[$&#123;mapred.<span class="built_in">min</span>.<span class="built_in">split</span>.<span class="built_in">size</span>&#125;,</span><br><span class="line">                <span class="built_in">min</span>($&#123;dfs.block.<span class="built_in">size</span>&#125;, $&#123;mapred.<span class="built_in">max</span>.<span class="built_in">split</span>.<span class="built_in">size</span>&#125;)]</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li><code>mapred.min.split.size</code>指的是数据的最小分割单元大小。  </li>
<li><code>mapred.max.split.size</code>指的是数据的最大分割单元大小。  </li>
<li><code>dfs.block.size</code>指的是HDFS设置的数据块大小。  </li>
</ul>
</blockquote>
<p>一般来说<code>dfs.block.size</code>这个值是一个已经指定好的值，而且这个参数hive是识别不到的：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="tag">hive</span>&gt; <span class="tag">set</span> <span class="tag">dfs</span><span class="class">.block</span><span class="class">.size</span>;</span><br><span class="line"><span class="tag">dfs</span><span class="class">.block</span><span class="class">.size</span> <span class="tag">is</span> <span class="tag">undefined</span></span><br></pre></td></tr></table></figure>
<p>所以实际上只有<code>mapred.min.split.size</code>和<code>mapred.max.split.size</code>这两个参数（本节内容后面就以min和max指代这两个参数）来决定map数量。在hive中min的默认值是1B，max的默认值是256MB：</p>
<figure class="highlight processing"><table><tr><td class="code"><pre><span class="line">hive&gt; <span class="built_in">set</span> mapred.<span class="built_in">min</span>.<span class="built_in">split</span>.<span class="built_in">size</span>;</span><br><span class="line">mapred.<span class="built_in">min</span>.<span class="built_in">split</span>.<span class="built_in">size</span>=<span class="number">1</span></span><br><span class="line">hive&gt; <span class="built_in">set</span> mapred.<span class="built_in">max</span>.<span class="built_in">split</span>.<span class="built_in">size</span>;</span><br><span class="line">mapred.<span class="built_in">max</span>.<span class="built_in">split</span>.<span class="built_in">size</span>=<span class="number">256000000</span></span><br></pre></td></tr></table></figure>
<p>所以如果不做修改的话，就是1个map task处理256MB数据，我们就以调整max为主。通过调整max可以起到调整map数的作用，减小max可以增加map数，增大max可以减少map数。需要提醒的是，直接调整<code>mapred.map.tasks</code>这个参数是没有效果的。</p>
<p>调整大小的时机根据查询的不同而不同，总的来讲可以通过观察map task的完成时间来确定是否需要增加map资源。如果map task的完成时间都是接近1分钟，甚至几分钟了，那么往往增加map数量，使得每个map task处理的数据量减少，能够让map task更快完成；而如果map task的运行时间已经很少了，比如10-20秒，这个时候增加map不太可能让map task更快完成，反而可能因为map需要的初始化时间反而让job总体速度变慢，这个时候反而需要考虑是否可以把map的数量减少，这样可以节省更多资源给其他Job。</p>
<h1 id="Reduce阶段的优化(reduce_phase)">Reduce阶段的优化(reduce phase)</h1><p>这里说的reduce阶段，是指前面流程图中的reduce phase（实际的reduce计算）而非图中整个reduce task。Reduce阶段优化的主要工作也是选择合适的reduce task数量，跟上面的map优化类似。<br>与map优化不同的是，reduce优化时，可以直接设置<code>mapred.reduce.tasks</code>参数从而直接指定reduce的个数。当然直接指定reduce个数虽然比较方便，但是不利于自动扩展。Reduce数的设置虽然相较map更灵活，但是也可以像map一样设定一个自动生成规则，这样运行定时job的时候就不用担心原来设置的固定reduce数会由于数据量的变化而不合适。</p>
<p>Hive估算reduce数量的时候，使用的是下面的公式：</p>
<figure class="highlight mel"><table><tr><td class="code"><pre><span class="line">num_reduce_tasks = <span class="keyword">min</span>[$&#123;hive.<span class="keyword">exec</span>.reducers.<span class="keyword">max</span>&#125;, </span><br><span class="line">                      ($&#123;input.<span class="keyword">size</span>&#125; / $&#123; hive.<span class="keyword">exec</span>.reducers.bytes.per.reducer&#125;)]</span><br></pre></td></tr></table></figure>
<p><code>hive.exec.reducers.bytes.per.reducer</code>默认为1G，也就是每个reduce处理相当于job输入文件中1G大小的对应数据量，而且reduce个数不能超过一个上限参数值，这个参数的默认取值为999。所以我们也可以用调整这个公式的方式调整reduce数量，在灵活性和定制性上取得一个平衡。</p>
<p>设置reduce数同样也是根据运行时间作为参考调整，并且可以根据特定的业务需求、工作负载类型总结出经验，所以不再赘述。</p>
<h1 id="Map与Reduce之间的优化(spill,_copy,_sort_phase)">Map与Reduce之间的优化(spill, copy, sort phase)</h1><p>map phase和reduce phase之间主要有3道工序。首先要把map输出的结果进行排序后做成中间文件，其次这个中间文件就能分发到各个reduce，最后reduce端在执行reduce phase之前把收集到的排序子文件合并成一个排序文件。这个部分可以调的参数挺多，但是一般都是不要调整的，不必重点关注。</p>
<h2 id="Spill_与_Sort">Spill 与 Sort</h2><p>在spill阶段，由于内存不够，数据可能没办法在内存中一次性排序完成，那么就只能把局部排序的文件先保存到磁盘上，这个动作叫spill，然后spill出来的多个文件可以在最后进行merge。如果发生spill，可以通过设置<code>io.sort.mb</code>来增大mapper输出buffer的大小，避免spill的发生。另外合并时可以通过设置<code>io.sort.factor</code>来使得一次性能够合并更多的数据。调试参数的时候，一个要看spill的时间成本，一个要看merge的时间成本，还需要注意不要撑爆内存（<code>io.sort.mb</code>是算在map的内存里面的）。Reduce端的merge也是一样可以用<code>io.sort.factor</code>。一般情况下这两个参数很少需要调整，除非很明确知道这个地方是瓶颈。</p>
<h2 id="Copy">Copy</h2><p>copy阶段是把文件从map端copy到reduce端。默认情况下在5%的map完成的情况下reduce就开始启动copy，这个有时候是很浪费资源的，因为reduce一旦启动就被占用，一直等到map全部完成，收集到所有数据才可以进行后面的动作，所以我们可以等比较多的map完成之后再启动reduce流程，这个比例可以通<code>mapred.reduce.slowstart.completed.maps</code>去调整，他的默认值就是5%。如果觉得这么做会减慢reduce端copy的进度，可以把copy过程的线程增大。<code>tasktracker.http.threads</code>可以决定作为server端的map用于提供数据传输服务的线程，<code>mapred.reduce.parallel.copies</code>可以决定作为client端的reduce同时从map端拉取数据的并行度（一次同时从多少个map拉数据），修改参数的时候这两个注意协调一下，server端能处理client端的请求即可。</p>
<h1 id="文件格式的优化">文件格式的优化</h1><p>文件格式方面有两个问题，一个是给输入和输出选择合适的文件格式，另一个则是小文件问题。小文件问题在目前的hive环境下已经得到了比较好的解决，hive的默认配置中就可以在小文件输入时自动把多个文件合并给1个map处理，输出时如果文件很小也会进行一轮单独的合并，所以这里就不专门讨论了。相关的参数可以在<a href="http://blog.csdn.net/yfkiss/article/details/8590486" target="_blank" rel="external">这里</a>找到。</p>
<p>关于文件格式，Hive0.9版本有3种，textfile，sequencefile和rcfile。总体上来说，rcfile的压缩比例和查询时间稍好一点，所以推荐使用。</p>
<p>关于使用方法，可以在建表结构时可以指定格式，然后指定压缩插入：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator"><span class="keyword">create</span> <span class="keyword">table</span> rc_file_test( <span class="keyword">col</span> <span class="built_in">int</span> ) <span class="keyword">stored</span> <span class="keyword">as</span> rcfile;</span></span><br><span class="line"><span class="operator"><span class="keyword">set</span> hive.exec.<span class="keyword">compress</span>.<span class="keyword">output</span> = <span class="literal">true</span>;</span></span><br><span class="line"><span class="operator"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> rc_file_test</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> source_table;</span></span><br></pre></td></tr></table></figure>
<p>另外时也可以指定输出格式，也可以通过<code>hive.default.fileformat</code>来设定输出格式，适用于create table as select的情况：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator"><span class="keyword">set</span> hive.<span class="keyword">default</span>.fileformat = SequenceFile;</span></span><br><span class="line"><span class="operator"><span class="keyword">set</span> hive.exec.<span class="keyword">compress</span>.<span class="keyword">output</span> = <span class="literal">true</span>;</span> </span><br><span class="line"><span class="comment">/*对于sequencefile，有record和block两种压缩方式可选，block压缩比更高*/</span></span><br><span class="line"><span class="operator"><span class="keyword">set</span> mapred.<span class="keyword">output</span>.compression.<span class="keyword">type</span> = <span class="keyword">BLOCK</span>;</span> </span><br><span class="line"><span class="operator"><span class="keyword">create</span> <span class="keyword">table</span> seq_file_test</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> source_table;</span></span><br></pre></td></tr></table></figure>
<p>上面的文件格式转换，其实是由hive完成的（也就是插入动作）。但是也可以由外部直接导入纯文本（可以按照<a href="http://slaytanic.blog.51cto.com/2057708/1162287" target="_blank" rel="external">这里</a>的做法预先压缩），或者是由MapReduce Job生成的数据。</p>
<p>值得注意的是，hive读取sequencefile的时候，是把key忽略的，也就是直接读value并且按照指定分隔符分隔字段。但是如果hive的数据来源是从mr生成的，那么写sequencefile的时候，key和value都是有意义的，key不能被忽略，而是应该当成第一个字段。为了解决这种不匹配的情况，有两种办法。一种是要求凡是结果会给hive用的mr job输出value的时候带上key。但是这样的话对于开发是一个负担，读写数据的时候都要注意这个情况。所以更好的方法是第二种，也就是把这个源自于hive的问题交给hive解决，写一个InputFormat包装一下，把value输出加上key即可。以下是核心代码，修改了RecordReader的next方法：</p>
<figure class="highlight processing"><table><tr><td class="code"><pre><span class="line"><span class="comment">//注意：这里为了简化，假定了key和value都是Text类型，所以MR的输出的k/v都要是Text类型。</span></span><br><span class="line"><span class="comment">//这个简化还会造成数据为空时，出现org.apache.hadoop.io.BytesWritable cannot be cast to org.apache.hadoop.io.Text的错误，因为默认hive的sequencefile的key是一个空的ByteWritable。</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="built_in">boolean</span> next(K <span class="variable">key</span>, V value) <span class="keyword">throws</span> IOException </span><br><span class="line">&#123;</span><br><span class="line">    Text tKey = (Text) <span class="variable">key</span>;</span><br><span class="line">    Text tValue = (Text) value;</span><br><span class="line">    <span class="keyword">if</span> (!<span class="keyword">super</span>.next(innerKey, innerValue)) </span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">    Text inner_key = (Text) innerKey; <span class="comment">//在构造函数中用createKey()生成</span></span><br><span class="line">    Text inner_value = (Text) innerValue; <span class="comment">//在构造函数中用createValue()生成</span></span><br><span class="line"></span><br><span class="line">    tKey.<span class="built_in">set</span>(inner_key);</span><br><span class="line">    tValue.<span class="built_in">set</span>(inner_key.toString() + <span class="string">'\t'</span> + inner_value.toString()); <span class="comment">// 分隔符注意自己定义</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="Job整体优化">Job整体优化</h1><p>有一些问题必须从job的整体角度去观察。这里讨论几个问题：Job执行模式（本地执行v.s.分布式执行）、JVM重用、索引、Join算法、数据倾斜。</p>
<h2 id="Job执行模式">Job执行模式</h2><p>Hadoop的map reduce job可以有3种模式执行，即本地模式，伪分布式，还有真正的分布式。本地模式和伪分布式都是在最初学习hadoop的时候往往被说成是做单机开发的时候用到。但是实际上对于处理数据量非常小的job，直接启动分布式job会消耗大量资源，而真正执行计算的时间反而非常少。这个时候就应该使用本地模式执行mr job，这样执行的时候不会启动分布式job，执行速度就会快很多。比如一般来说启动分布式job，无论多小的数据量，执行时间一般不会少于20s，而使用本地mr模式，10秒左右就能出结果。</p>
<p>设置执行模式的主要参数有三个，一个是<code>hive.exec.mode.local.auto</code>，把他设为true就能够自动开启local mr模式。但是这还不足以启动local mr，输入的文件数量和数据量大小必须要控制，这两个参数分别为<code>hive.exec.mode.local.auto.tasks.max</code>和<code>hive.exec.mode.local.auto.inputbytes.max</code>，默认值分别为4和128MB，即默认情况下，map处理的文件数不超过4个并且总大小小于128MB就启用local mr模式。</p>
<p>另外，如果是简单的select语句，比如select某个列取个10条数据看看sample，那么在hive0.10之后有专门的fetch task优化，使用参数<code>hive.fetch.task.conversion</code>即可。</p>
<h2 id="JVM重用">JVM重用</h2><p>正常情况下，MapReduce启动的JVM在完成一个task之后就退出了，但是如果任务花费时间很短，又要多次启动JVM的情况下（比如对很大数据量进行计数操作），JVM的启动时间就会变成一个比较大的overhead。在这种情况下，可以使用jvm重用的参数：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator"><span class="keyword">set</span> mapred.job.<span class="keyword">reuse</span>.jvm.<span class="keyword">num</span>.tasks = <span class="number">5</span>;</span></span><br></pre></td></tr></table></figure>
<p>他的作用是让一个jvm运行多次任务之后再退出。这样一来也能节约不少JVM启动时间。</p>
<h2 id="索引">索引</h2><p>总体上来说，hive的索引目前还是一个不太适合使用的东西，这里只是考虑到叙述完整性，对其进行基本的介绍。</p>
<p>Hive中的索引架构开放了一个接口，允许你根据这个接口去实现自己的索引。目前hive自己有一个参考的索引实现（CompactIndex），后来在0.8版本中又加入位图索引。这里就讲讲CompactIndex。</p>
<p>CompactIndex的实现原理类似一个lookup table，而非传统数据库中的B树。如果你对table A的col1做了索引，索引文件本身就是一个table，这个table会有3列，分别是col1的枚举值，每个值对应的数据文件位置，以及在这个文件位置中的偏移量。通过这种方式，可以减少你查询的数据量（偏移量可以告诉你从哪个位置开始找，自然只需要定位到相应的block），起到减少资源消耗的作用。但是就其性能来说，并没有很大的改善，很可能还不如构建索引需要花的时间。所以在集群资源充足的情况下，没有太大必要考虑索引。</p>
<p>CompactIndex的还有一个缺点就是使用起来不友好，索引建完之后，使用之前还需要根据查询条件做一个同样剪裁才能使用，索引的内部结构完全暴露，而且还要花费额外的时间。具体看看下面的使用方法就了解了：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*在index_test_table表的id字段上创建索引*/</span></span><br><span class="line"><span class="operator"><span class="keyword">create</span> <span class="keyword">index</span> idx <span class="keyword">on</span> <span class="keyword">table</span> index_test_table(<span class="keyword">id</span>)  </span><br><span class="line"><span class="keyword">as</span> <span class="string">'org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler'</span> <span class="keyword">with</span> <span class="keyword">deferred</span> <span class="keyword">rebuild</span>;</span></span><br><span class="line"><span class="operator"><span class="keyword">alter</span> <span class="keyword">index</span> idx <span class="keyword">on</span> index_test_table <span class="keyword">rebuild</span>;</span></span><br><span class="line">	</span><br><span class="line"><span class="comment">/*索引的剪裁。找到上面建的索引表，根据你最终要用的查询条件剪裁一下。*/</span></span><br><span class="line"><span class="comment">/*如果你想跟RDBMS一样建完索引就用，那是不行的，会直接报错，这也是其麻烦的地方*/</span></span><br><span class="line"><span class="operator"><span class="keyword">create</span> <span class="keyword">table</span> my_index</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> _bucketname, <span class="string">`_offsets`</span></span><br><span class="line"><span class="keyword">from</span> default__index_test_table_idx__ <span class="keyword">where</span> <span class="keyword">id</span> = <span class="number">10</span>;</span></span><br><span class="line">	</span><br><span class="line"><span class="comment">/*现在可以用索引了，注意最终查询条件跟上面的剪裁条件一致*/</span></span><br><span class="line"><span class="operator"><span class="keyword">set</span> hive.<span class="keyword">index</span>.<span class="keyword">compact</span>.<span class="keyword">file</span> = /<span class="keyword">user</span>/hive/warehouse/my_index;</span> </span><br><span class="line"><span class="operator"><span class="keyword">set</span> hive.<span class="keyword">input</span>.<span class="keyword">format</span> = org.apache.hadoop.hive.ql.<span class="keyword">index</span>.<span class="keyword">compact</span>.HiveCompactIndexInputFormat;</span></span><br><span class="line"><span class="operator"><span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> index_test_table <span class="keyword">where</span> <span class="keyword">id</span> = <span class="number">10</span>;</span></span><br></pre></td></tr></table></figure>
<h2 id="Join算法">Join算法</h2><p>处理分布式join，一般有两种方法:</p>
<blockquote>
<ul>
<li>replication join：把其中一个表复制到所有节点，这样另一个表在每个节点上面的分片就可以跟这个完整的表join了；  </li>
<li>repartition join：把两份数据按照join key进行hash重分布，让每个节点处理hash值相同的join key数据，也就是做局部的join。  </li>
</ul>
</blockquote>
<p>这两种方式在M/R Job中分别对应了map side join和reduce side join。在一些MPP DB中，数据可以按照某列字段预先进行hash分布，这样在跟这个表以这个字段为join key进行join的时候，该表肯定不需要做数据重分布了，这种功能是以HDFS作为底层文件系统的hive所没有的。</p>
<p>在默认情况下，hive的join策略是进行reduce side join。当两个表中有一个是小表的时候，就可以考虑用map join了，因为小表复制的代价会好过大表shuffle的代价。使用map join的配置方法有两种，一种直接在sql中写hint，语法是<code>/*+MAPJOIN (tbl)*/</code>，其中tbl就是你想要做replication的表。另一种方法是设置<code>hive.auto.convert.join = true</code>，这样hive会自动判断当前的join操作是否合适做map join，主要是找join的两个表中有没有小表。至于多大的表算小表，则是由<code>hive.smalltable.filesize</code>决定，默认25MB。</p>
<p>但是有的时候，没有一个表足够小到能够放进内存，但是还是想用map join怎么办？这个时候就要用到bucket map join。其方法是两个join表在join key上都做hash bucket，并且把你打算复制的那个（相对）小表的bucket数设置为大表的倍数。这样数据就会按照join key做hash bucket。小表依然复制到所有节点，map join的时候，小表的每一组bucket加载成hashtable，与对应的一个大表bucket做局部join，这样每次只需要加载部分hashtable就可以了。<br>然后在两个表的join key都具有唯一性的时候（也就是可做主键），还可以进一步做sort merge bucket map join。做法还是两边要做hash bucket，而且每个bucket内部要进行排序。这样一来当两边bucket要做局部join的时候，只需要用类似merge sort算法中的merge操作一样把两个bucket顺序遍历一遍即可完成，这样甚至都不用把一个bucket完整的加载成hashtable，这对性能的提升会有很大帮助。<br>然后这里以一个完整的实验说明这几种join算法如何操作。<br>首先建表要带上bucket：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator"><span class="keyword">create</span> <span class="keyword">table</span> map_join_test(<span class="keyword">id</span> <span class="built_in">int</span>)</span><br><span class="line">clustered <span class="keyword">by</span> (<span class="keyword">id</span>) sorted <span class="keyword">by</span> (<span class="keyword">id</span>) <span class="keyword">into</span> <span class="number">32</span> buckets</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> textfile;</span></span><br></pre></td></tr></table></figure>
<p>然后插入我们准备好的800万行数据，注意要强制划分成bucket（也就是用reduce划分hash值相同的数据到相同的文件）：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator"><span class="keyword">set</span> hive.enforce.bucketing = <span class="literal">true</span>;</span></span><br><span class="line"><span class="operator"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> map_join_test</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> map_join_source_data;</span></span><br></pre></td></tr></table></figure>
<p>这样这个表就有了800万id值（且里面没有重复值，所以可以做sort merge），占用80MB左右。<br>接下来我们就可以一一尝试map join的算法了。首先是普通的map join：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator"><span class="keyword">select</span> <span class="comment">/*+mapjoin(a) */</span><span class="keyword">count</span>(*)</span><br><span class="line"><span class="keyword">from</span> map_join_test a</span><br><span class="line"><span class="keyword">join</span> map_join_test b <span class="keyword">on</span> a.<span class="keyword">id</span> = b.<span class="keyword">id</span>;</span></span><br></pre></td></tr></table></figure>
<p>然后就会看到分发hash table的过程：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="number">2013</span>-<span class="number">08</span>-<span class="number">31</span> <span class="number">09</span>:<span class="number">08</span>:<span class="number">43</span>     Starting to launch local task to process <span class="built_in">map</span> join;      maximum memory = <span class="number">1004929024</span></span><br><span class="line"><span class="number">2013</span>-<span class="number">08</span>-<span class="number">31</span> <span class="number">09</span>:<span class="number">08</span>:<span class="number">45</span>     Processing rows:   <span class="number">200000</span>  Hashtable size: <span class="number">199999</span>  Memory usage:   <span class="number">38823016</span>        rate:   <span class="number">0.039</span></span><br><span class="line"><span class="number">2013</span>-<span class="number">08</span>-<span class="number">31</span> <span class="number">09</span>:<span class="number">08</span>:<span class="number">46</span>     Processing rows:   <span class="number">300000</span>  Hashtable size: <span class="number">299999</span>  Memory usage:   <span class="number">56166968</span>        rate:   <span class="number">0.056</span></span><br><span class="line">……</span><br><span class="line"><span class="number">2013</span>-<span class="number">08</span>-<span class="number">31</span> <span class="number">09</span>:<span class="number">12</span>:<span class="number">39</span>     Processing rows:  <span class="number">4900000</span> Hashtable size: <span class="number">4899999</span> Memory usage:   <span class="number">896968104</span>       rate:   <span class="number">0.893</span></span><br><span class="line"><span class="number">2013</span>-<span class="number">08</span>-<span class="number">31</span> <span class="number">09</span>:<span class="number">12</span>:<span class="number">47</span>     Processing rows:  <span class="number">5000000</span> Hashtable size: <span class="number">4999999</span> Memory usage:   <span class="number">922733048</span>       rate:   <span class="number">0.918</span></span><br><span class="line">Execution failed with <span class="built_in">exit</span> status: <span class="number">2</span></span><br><span class="line">Obtaining error information</span><br><span class="line"></span><br><span class="line">Task failed!</span><br><span class="line">Task ID:</span><br><span class="line">  Stage-<span class="number">4</span></span><br></pre></td></tr></table></figure>
<p>不幸的是，居然内存不够了，直接做map join失败了。但是80MB的大小为何用1G的heap size都放不下？观察整个过程就会发现，平均一条记录需要用到200字节的存储空间，这个overhead太大了，对于map join的小表size一定要好好评估，如果有几十万记录数就要小心了。虽然不太清楚其中的构造原理，但是在互联网上也能找到其他的例证，比如<a href="http://blog.csdn.net/jmydream/article/details/7942529" target="_blank" rel="external">这里</a>和<a href="http://dennyglee.com/2013/04/26/optimizing-joins-running-on-hdinsight-hive-on-azure-at-gfs/" target="_blank" rel="external">这里</a>,平均一行500字节左右。这个明显比一般的表一行占用的数据量要大。不过hive也在做这方面的改进，争取缩小hash table，比如<a href="https://issues.apache.org/jira/browse/HIVE-6430" target="_blank" rel="external">HIVE-6430</a>。</p>
<p>所以接下来我们就用bucket map join，之前分的bucket就派上用处了。只需要在上述sql的前面加上如下的设置：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator"><span class="keyword">set</span> hive.<span class="keyword">optimize</span>.bucketmapjoin = <span class="literal">true</span>;</span></span><br></pre></td></tr></table></figure>
<p>然后还是会看到hash table分发：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="number">2013</span>-<span class="number">08</span>-<span class="number">31</span> <span class="number">09</span>:<span class="number">20</span>:<span class="number">39</span>     Starting to launch local task to process <span class="built_in">map</span> join;      maximum memory = <span class="number">1004929024</span></span><br><span class="line"><span class="number">2013</span>-<span class="number">08</span>-<span class="number">31</span> <span class="number">09</span>:<span class="number">20</span>:<span class="number">41</span>     Processing rows:   <span class="number">200000</span>  Hashtable size: <span class="number">199999</span>  Memory usage:   <span class="number">38844832</span>        rate:   <span class="number">0.039</span></span><br><span class="line"><span class="number">2013</span>-<span class="number">08</span>-<span class="number">31</span> <span class="number">09</span>:<span class="number">20</span>:<span class="number">42</span>     Processing rows:   <span class="number">275567</span>  Hashtable size: <span class="number">275567</span>  Memory usage:   <span class="number">51873632</span>        rate:   <span class="number">0.052</span></span><br><span class="line"><span class="number">2013</span>-<span class="number">08</span>-<span class="number">31</span> <span class="number">09</span>:<span class="number">20</span>:<span class="number">42</span>     Dump the hashtable into file: file:/tmp/hadoop/hive_2013-<span class="number">08</span>-<span class="number">31</span>_21-<span class="number">20</span>-<span class="number">37</span>_444_1135806892100127714/-local-<span class="number">10003</span>/HashTable-Stage-<span class="number">1</span>/MapJoin-a-<span class="number">10</span>-<span class="number">000000</span>_0.hashtable</span><br><span class="line"><span class="number">2013</span>-<span class="number">08</span>-<span class="number">31</span> <span class="number">09</span>:<span class="number">20</span>:<span class="number">46</span>     Upload <span class="number">1</span> File to: file:/tmp/hadoop/hive_2013-<span class="number">08</span>-<span class="number">31</span>_21-<span class="number">20</span>-<span class="number">37</span>_444_1135806892100127714/-local-<span class="number">10003</span>/HashTable-Stage-<span class="number">1</span>/MapJoin-a-<span class="number">10</span>-<span class="number">000000</span>_0.hashtable File size: <span class="number">11022975</span></span><br><span class="line"><span class="number">2013</span>-<span class="number">08</span>-<span class="number">31</span> <span class="number">09</span>:<span class="number">20</span>:<span class="number">47</span>     Processing rows:   <span class="number">300000</span>  Hashtable size: <span class="number">24432</span>   Memory usage:   <span class="number">8470976</span> rate:   <span class="number">0.008</span></span><br><span class="line"><span class="number">2013</span>-<span class="number">08</span>-<span class="number">31</span> <span class="number">09</span>:<span class="number">20</span>:<span class="number">47</span>     Processing rows:   <span class="number">400000</span>  Hashtable size: <span class="number">124432</span>  Memory usage:   <span class="number">25368080</span>        rate:   <span class="number">0.025</span></span><br><span class="line"><span class="number">2013</span>-<span class="number">08</span>-<span class="number">31</span> <span class="number">09</span>:<span class="number">20</span>:<span class="number">48</span>     Processing rows:   <span class="number">500000</span>  Hashtable size: <span class="number">224432</span>  Memory usage:   <span class="number">42968080</span>        rate:   <span class="number">0.043</span></span><br><span class="line"><span class="number">2013</span>-<span class="number">08</span>-<span class="number">31</span> <span class="number">09</span>:<span class="number">20</span>:<span class="number">49</span>     Processing rows:   <span class="number">551527</span>  Hashtable size: <span class="number">275960</span>  Memory usage:   <span class="number">52022488</span>        rate:   <span class="number">0.052</span></span><br><span class="line"><span class="number">2013</span>-<span class="number">08</span>-<span class="number">31</span> <span class="number">09</span>:<span class="number">20</span>:<span class="number">49</span>     Dump the hashtable into file: file:/tmp/hadoop/hive_2013-<span class="number">08</span>-<span class="number">31</span>_21-<span class="number">20</span>-<span class="number">37</span>_444_1135806892100127714/-local-<span class="number">10003</span>/HashTable-Stage-<span class="number">1</span>/MapJoin-a-<span class="number">10</span>-<span class="number">000001</span>_0.hashtable</span><br><span class="line">……</span><br></pre></td></tr></table></figure>
<p>这次就会看到每次构建完一个hash table（也就是所对应的对应一个bucket），会把这个hash table写入文件，重新构建新的hash table。这样一来由于每个hash table的量比较小，也就不会有内存不足的问题，整个sql也能成功运行。不过光光是这个复制动作就要花去3分半的时间，所以如果整个job本来就花不了多少时间的，那这个时间就不可小视。</p>
<p>最后我们试试sort merge bucket map join，在bucket map join的基础上加上下面的设置即可：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator"><span class="keyword">set</span> hive.<span class="keyword">optimize</span>.bucketmapjoin.sortedmerge = <span class="literal">true</span>;</span></span><br><span class="line"><span class="operator"><span class="keyword">set</span> hive.<span class="keyword">input</span>.<span class="keyword">format</span> = org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat;</span></span><br></pre></td></tr></table></figure>
<p>sort merge bucket map join是不会产生hash table复制的步骤的，直接开始做实际map端join操作了，数据在join的时候边做边读。跳过复制的步骤，外加join算法的改进，使得sort merge bucket map join的效率要明显好于bucket map join。</p>
<p>关于join的算法虽然有这么些选择，但是个人觉得，对于日常使用，掌握默认的reduce join和普通的（无bucket）map join已经能解决大多数问题。如果小表不能完全放内存，但是小表相对大表的size量级差别也非常大的时候，或者是必须要做cross join，那也可以试试bucket map join，不过其hash table分发的过程会浪费不少时间，需要评估下是否能够比reduce join更高效。而sort merge bucket map join虽然性能不错，但是把数据做成bucket本身也需要时间，另外其发动条件比较特殊，就是两边join key必须都唯一（很多介绍资料中都不提这一点。强调下必须都是唯一，哪怕只有一个表不唯一，出来的结果也是错的。当然，其实这点完全可以根据其算法原理推敲出来）。这样的场景相对比较少见，“用户基本表 join 用户扩展表”以及“用户今天的数据快照 join 用户昨天的数据快照”这类场景可能比较合适。</p>
<p>这里顺便说个题外话，在数据仓库中，小表往往是维度表，而小表map join这件事情其实用udf代替还会更快，因为不用单独启动一轮job，所以这也是一种可选方案。当然前提条件是维度表是固定的自然属性（比如日期），只增加不修改（比如网站的页面编号）的情况也可以考虑。如果维度有更新，要做缓慢变化维的，当然还是维表好维护。至于维表原本的一个主要用途OLAP，以Hive目前的性能是没法实现的，也就不需要多虑了。</p>
<h2 id="数据倾斜">数据倾斜</h2><p>所谓数据倾斜，说的是由于数据分布不均匀，个别值集中占据大部分数据量，加上hadoop的计算模式，导致计算资源不均匀引起性能下降。下图就是一个例子：</p>
<p><img src="http://7xltg5.com1.z0.glb.clouddn.com/mr_skew.jpg" alt="mr_skew"></p>
<p>还是拿网站的访问日志说事吧。假设网站访问日志中会记录用户的<code>user_id</code>，并且对于注册用户使用其用户表的<code>user_id</code>，对于非注册用户使用一个<code>user_id = 0</code>代表。那么鉴于大多数用户是非注册用户（只看不写），所以<code>user_id = 0</code>占据了绝大多数。而如果进行计算的时候如果以<code>user_id</code>作为group by的维度或者是join key，那么个别reduce会收到比其他reduce多得多的数据——因为它要接收所有<code>user_id = 0</code>的记录进行处理，使得其处理效果会非常差，其他reduce都跑完很久了它还在运行。</p>
<p>倾斜分成group by造成的倾斜和join造成的倾斜，需要分开看。</p>
<p>group by造成的倾斜有两个参数可以解决，一个是<code>hive.map.aggr</code>，默认值已经为true，他的意思是做map aggregation，也就是在mapper里面做聚合。这个方法不同于直接写mapreduce的时候可以实现的combiner，事实上各种基于mr的框架如pig，cascading等等用的都是map aggregation（或者叫partial aggregation）而非combiner的策略，也就是在mapper里面直接做聚合操作而不是输出到buffer给combiner做聚合。对于map aggregation，hive还会做检查，如果aggregation的效果不好，那么hive会自动放弃map aggregation。判断效果的依据就是经过一小批数据的处理之后，检查聚合后的数据量是否减小到一定的比例，默认是0.5，由<code>hive.map.aggr.hash.min.reduction</code>这个参数控制。所以如果确认数据里面确实有个别取值倾斜，但是大部分值是比较稀疏的，这个时候可以把比例强制设为1，避免极端情况下map aggr失效。<code>hive.map.aggr</code>还有一些相关参数，比如map aggr的内存占用，具体可以参考<a href="http://dev.bizo.com/2013/02/map-side-aggregations-in-apache-hive.html" target="_blank" rel="external">这篇文章</a>。另一个参数是<code>hive.groupby.skewindata</code>。这个参数的意思是做reduce操作的时候，拿到的key并不是所有相同值给同一个reduce，而是随机分发，然后reduce做聚合，做完之后再做一轮MR，拿前面聚合过的数据再算结果。所以这个参数其实跟<code>hive.map.aggr</code>做的是类似的事情，只是拿到reduce端来做，而且要额外启动一轮job，所以其实不怎么推荐用，效果不明显。</p>
<p>如果碰到count distinct的情况需要优化，改写SQL是一个比较简便的方法，可以按照下面这么做：</p>
<figure class="highlight nimrod"><table><tr><td class="code"><pre><span class="line">/*改写前*/</span><br><span class="line">select a, count(<span class="keyword">distinct</span> b) <span class="keyword">as</span> c <span class="keyword">from</span> tbl group by a;</span><br><span class="line">/*改写后*/</span><br><span class="line">select a, count(*) <span class="keyword">as</span> c</span><br><span class="line"><span class="keyword">from</span> (select <span class="keyword">distinct</span> a, b <span class="keyword">from</span> tbl) group by a;</span><br></pre></td></tr></table></figure>
<p>join造成的倾斜，就比如上面描述的网站访问日志和用户表两个表join：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator"><span class="keyword">select</span> a.* <span class="keyword">from</span> <span class="keyword">logs</span> a <span class="keyword">join</span> <span class="keyword">users</span> b <span class="keyword">on</span> a.user_id = b.user_id;</span></span><br></pre></td></tr></table></figure>
<p>hive给出的解决方案叫skew join，其原理把这种<code>user_id = 0</code>的特殊值先不在reduce端计算掉，而是先写入hdfs，然后启动一轮map join专门做这个特殊值的计算，期望能提高计算这部分值的处理速度。当然你要告诉hive这个join是个skew join，即：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator"><span class="keyword">set</span> hive.<span class="keyword">optimize</span>.skewjoin = <span class="literal">true</span>;</span></span><br></pre></td></tr></table></figure>
<p>还有要告诉hive如何判断特殊值，根据<code>hive.skewjoin.key</code>设置的数量hive可以知道，比如默认值是100000，那么超过100000条记录的值就是特殊值。<br>skew join的流程可以用下图描述：</p>
<p><img src="http://7xltg5.com1.z0.glb.clouddn.com/skew_join.jpg" alt="skew_join"></p>
<p>另外对于特殊值的处理往往跟业务有关系，所以也可以从业务角度重写sql解决。比如前面这种倾斜join，可以把特殊值隔离开来（从业务角度说，users表应该不存在<code>user_id = 0</code>的情况，但是这里还是假设有这个值，使得这个写法更加具有通用性）：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator"><span class="keyword">select</span> a.* <span class="keyword">from</span> </span><br><span class="line">(</span><br><span class="line"><span class="keyword">select</span> a.*</span><br><span class="line"><span class="keyword">from</span> (<span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">logs</span> <span class="keyword">where</span> user_id = <span class="number">0</span>)  a </span><br><span class="line"><span class="keyword">join</span> (<span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">users</span> <span class="keyword">where</span> user_id = <span class="number">0</span>) b </span><br><span class="line"><span class="keyword">on</span> a.user_id =  b.user_id</span><br><span class="line"><span class="keyword">union</span> all</span><br><span class="line"><span class="keyword">select</span> a.* </span><br><span class="line"><span class="keyword">from</span> <span class="keyword">logs</span> a <span class="keyword">join</span> <span class="keyword">users</span> b</span><br><span class="line"><span class="keyword">on</span> a.user_id &lt;&gt; <span class="number">0</span> <span class="keyword">and</span> a.user_id = b.user_id</span><br><span class="line">)<span class="keyword">t</span>;</span></span><br></pre></td></tr></table></figure>
<p>大部分时候倾斜是因为某一个特殊值，但是也有极端的情况是因为<strong>某一类特殊值</strong>，这往往是业务设计造成。比如对于商品<code>item_id</code>的编码，除了本身的id序列，还人为的把item的类型也作为编码放在最后两位，这样如果类型1的编码是00，类型2的编码是01，并且类型1是主要商品类，将会造成以00为结尾的商品整体倾斜。这时，如果reduce的数量恰好是100的整数倍，会造成partitioner把00结尾的<code>item_id</code>都hash到同一个reducer，引爆问题。当然，这种情况解决不难，只需要设置合适的reduce值，但是这种坑就会比较隐蔽。</p>
<h1 id="SQL整体优化">SQL整体优化</h1><p>前面对于单个job如何做优化已经做过详细讨论，但是hive查询会生成多个job，针对多个job，有什么地方需要优化？</p>
<h2 id="Job间并行">Job间并行</h2><p>首先，在hive生成的多个job中，在有些情况下job之间是可以并行的，典型的就是子查询。当需要执行多个子查询union all或者join操作的时候，job间并行就可以使用了。比如下面的代码就是一个可以并行的场景示意：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator"><span class="keyword">select</span> * <span class="keyword">from</span> </span><br><span class="line">(</span><br><span class="line">   <span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> <span class="keyword">logs</span> </span><br><span class="line">   <span class="keyword">where</span> log_date = <span class="number">20130801</span> <span class="keyword">and</span> item_id = <span class="number">1</span></span><br><span class="line">   <span class="keyword">union</span> all </span><br><span class="line">   <span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> <span class="keyword">logs</span> </span><br><span class="line">   <span class="keyword">where</span> log_date = <span class="number">20130802</span> <span class="keyword">and</span> item_id = <span class="number">2</span></span><br><span class="line">   <span class="keyword">union</span> all </span><br><span class="line">   <span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> <span class="keyword">logs</span> </span><br><span class="line">   <span class="keyword">where</span> log_date = <span class="number">20130803</span> <span class="keyword">and</span> item_id = <span class="number">3</span></span><br><span class="line">)<span class="keyword">t</span></span></span><br></pre></td></tr></table></figure>
<p>设置job间并行的参数是<code>hive.exec.parallel</code>，将其设为true即可。默认的并行度为8，也就是最多允许sql中8个job并行。如果想要更高的并行度，可以通过<code>hive.exec.parallel. thread.number</code>参数进行设置，但要避免设置过大而占用过多资源。</p>
<h2 id="减少Job数">减少Job数</h2><p>另外在实际开发过程中也发现，一些实现思路会导致生成多余的job而显得不够高效。比如这个需求：查询某网站日志中同时访问过页面a和页面b的用户数量。低效的思路是面向明细的，先取出看过页面a的用户，再取出看过页面b的用户，然后取交集，代码如下：</p>
<figure class="highlight nimrod"><table><tr><td class="code"><pre><span class="line">select count(*) </span><br><span class="line"><span class="keyword">from</span> </span><br><span class="line">(select <span class="keyword">distinct</span> user_id </span><br><span class="line"><span class="keyword">from</span> logs where page_name = 'a') a</span><br><span class="line">join </span><br><span class="line">(select <span class="keyword">distinct</span> user_id </span><br><span class="line"><span class="keyword">from</span> logs where blog_owner = 'b') b </span><br><span class="line">on a.user_id = b.user_id;</span><br></pre></td></tr></table></figure>
<p>这样一来，就要产生2个求子查询的job，一个用于关联的job，还有一个计数的job，一共有4个job。<br>但是我们直接用面向统计的方法去计算的话（也就是用group by替代join），则会更加符合M/R的模式，只需要用两个job就能跑完：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator"><span class="keyword">select</span> <span class="keyword">count</span> (*) <span class="keyword">from</span> (</span><br><span class="line"><span class="keyword">select</span> user_id </span><br><span class="line"><span class="keyword">from</span> <span class="keyword">logs</span> <span class="keyword">group</span> <span class="keyword">by</span> user_id</span><br><span class="line"><span class="keyword">having</span> (<span class="keyword">count</span>(<span class="keyword">case</span> <span class="keyword">when</span> page_name = <span class="string">'a'</span> <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">end</span>) *</span><br><span class="line">        <span class="keyword">count</span>(<span class="keyword">case</span> <span class="keyword">when</span> page_name = <span class="string">'b'</span> <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">end</span>) &gt; <span class="number">0</span>)</span><br><span class="line">)<span class="keyword">t</span>;</span></span><br></pre></td></tr></table></figure>
<p>第一种查询方法符合思考问题的直觉，是工程师和分析师在实际查数据中最先想到的写法，但是如果在目前hive的query planner不是那么智能的情况下，想要更加快速的跑出结果，懂一点工具的内部机理也是必须的。</p>
<p><strong>2015.01 updated:</strong> 最近本文被CSDN<a href="http://www.csdn.net/article/2015-01-13/2823530" target="_blank" rel="external">转载</a>。时隔一年多，hive已经有了很多变化，当然本文中的方法都还是适用的。本文中的一些内容（比如存储格式）已经有了更好的解决办法，在我比较新的blog中也有间接的体现。但是碍于精力有限，不会专门在本文中更新相关内容了。另外有网友指出原来文章中最后一段代码是有问题的，经检查确实是我的疏忽，描述也略有问题，现已在本文中改正。当然原有代码体现出来的思路是没有问题的，主要是语法细节的错误。</p>
<p><strong>2015.12 updated:</strong> 更新了关于<code>hive.map.aggr</code>的解释，并且补充了因为对字段人为编码而造成的数据倾斜的案例。</p>
</span>
      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/hive/" rel="tag">#hive</a>
          
            <a href="/tags/sql-on-hadoop/" rel="tag">#sql on hadoop</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-prev post-nav-item">
            
              <a href="/2014/03/06/mac-osx上安装hadoop2/" rel="prev">Mac OSX上安装Hadoop2</a>
            
          </div>

          <div class="post-nav-next post-nav-item">
            
              <a href="/2013/04/30/数据仓库中的sql性能优化（mysql篇）/" rel="next">数据仓库中的sql性能优化（MySQL篇）</a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>

 </div>

        

        
          <div class="comments" id="comments">
            
              <div class="ds-thread" data-thread-key="2013/09/01/数据仓库中的sql性能优化（hive篇）/"
                   data-title="数据仓库中的SQL性能优化（Hive篇）" data-url="http://sunyi514.github.io/2013/09/01/数据仓库中的sql性能优化（hive篇）/">
              </div>
            
          </div>
        
      </div>

      
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" src="http://7xltg5.com1.z0.glb.clouddn.com/author.jpg" alt="奔跑的兔子" itemprop="image"/>
          <p class="site-author-name" itemprop="name">奔跑的兔子</p>
        </div>
        <p class="site-description motion-element" itemprop="description"></p>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">7</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          <div class="site-state-item site-state-categories">
            <a href="/categories">
              <span class="site-state-item-count">1</span>
              <span class="site-state-item-name">分类</span>
              </a>
          </div>

          <div class="site-state-item site-state-tags">
            <a href="/tags">
              <span class="site-state-item-count">9</span>
              <span class="site-state-item-name">标签</span>
              </a>
          </div>

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/u/1731546452" target="_blank">weibo</a>
              </span>
            
          
        </div>

        
        

        <div class="links-of-author motion-element">
          
        </div>

      </section>

      
        <section class="post-toc-wrap sidebar-panel-active">
          <div class="post-toc-indicator-top post-toc-indicator"></div>
          <div class="post-toc">
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Map阶段的优化(map_phase)"><span class="nav-number">1.</span> <span class="nav-text">Map阶段的优化(map phase)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Reduce阶段的优化(reduce_phase)"><span class="nav-number">2.</span> <span class="nav-text">Reduce阶段的优化(reduce phase)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Map与Reduce之间的优化(spill,_copy,_sort_phase)"><span class="nav-number">3.</span> <span class="nav-text">Map与Reduce之间的优化(spill, copy, sort phase)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Spill_与_Sort"><span class="nav-number">3.1.</span> <span class="nav-text">Spill 与 Sort</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Copy"><span class="nav-number">3.2.</span> <span class="nav-text">Copy</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#文件格式的优化"><span class="nav-number">4.</span> <span class="nav-text">文件格式的优化</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Job整体优化"><span class="nav-number">5.</span> <span class="nav-text">Job整体优化</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Job执行模式"><span class="nav-number">5.1.</span> <span class="nav-text">Job执行模式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#JVM重用"><span class="nav-number">5.2.</span> <span class="nav-text">JVM重用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#索引"><span class="nav-number">5.3.</span> <span class="nav-text">索引</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Join算法"><span class="nav-number">5.4.</span> <span class="nav-text">Join算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据倾斜"><span class="nav-number">5.5.</span> <span class="nav-text">数据倾斜</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#SQL整体优化"><span class="nav-number">6.</span> <span class="nav-text">SQL整体优化</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Job间并行"><span class="nav-number">6.1.</span> <span class="nav-text">Job间并行</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#减少Job数"><span class="nav-number">6.2.</span> <span class="nav-text">减少Job数</span></a></li></ol></li></ol></div>
            
          </div>
          <div class="post-toc-indicator-bottom post-toc-indicator"></div>
        </section>
      

    </div>
  </aside>


    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner"> <div class="copyright" >
  
  &copy; &nbsp;  2013 - 
  <span itemprop="copyrightYear">2015</span>
  <span class="with-love">
    <i class="icon-next-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">奔跑的兔子</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


 </div>
    </footer>

    <div class="back-to-top"></div>
  </div>

  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  
  
    

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"sunyi514"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>
    
     
     
  	<script src="/js/ua-parser.min.js"></script>
  	<script src="/js/hook-duoshuo.js"></script>
  

    
  
  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/fancy-box.js?v=0.4.5.1"></script>


  <script type="text/javascript" src="/js/helpers.js?v=0.4.5.1"></script>
  

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/js/motion_global.js?v=0.4.5.1" id="motion.global"></script>




  <script type="text/javascript" src="/js/nav-toggle.js?v=0.4.5.1"></script>
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  
<script type="text/javascript" src="/js/bootstrap.scrollspy.js?v=0.4.5.1" id="bootstrap.scrollspy.custom"></script>


<script type="text/javascript" id="sidebar.toc.highlight">
  $(document).ready(function () {
    var tocSelector = '.post-toc';
    var $tocSelector = $(tocSelector);
    var activeCurrentSelector = '.active-current';

    $tocSelector
      .on('activate.bs.scrollspy', function () {
        var $currentActiveElement = $(tocSelector + ' .active').last();

        removeCurrentActiveClass();
        $currentActiveElement.addClass('active-current');

        $tocSelector[0].scrollTop = $currentActiveElement.position().top;
      })
      .on('clear.bs.scrollspy', function () {
        removeCurrentActiveClass();
      });

    function removeCurrentActiveClass () {
      $(tocSelector + ' ' + activeCurrentSelector)
        .removeClass(activeCurrentSelector.substring(1));
    }

    function processTOC () {
      getTOCMaxHeight();
      toggleTOCOverflowIndicators();
    }

    function getTOCMaxHeight () {
      var height = $('.sidebar').height() -
                   $tocSelector.position().top -
                   $('.post-toc-indicator-bottom').height();

      $tocSelector.css('height', height);

      return height;
    }

    function toggleTOCOverflowIndicators () {
      tocOverflowIndicator(
        '.post-toc-indicator-top',
        $tocSelector.scrollTop() > 0 ? 'show' : 'hide'
      );

      tocOverflowIndicator(
        '.post-toc-indicator-bottom',
        $tocSelector.scrollTop() >= $tocSelector.find('ol').height() - $tocSelector.height() ? 'hide' : 'show'
      )
    }

    $(document).on('sidebar.motion.complete', function () {
      processTOC();
    });

    $('body').scrollspy({ target: tocSelector });
    $(window).on('resize', function () {
      if ( $('.sidebar').hasClass('sidebar-active') ) {
        processTOC();
      }
    });

    onScroll($tocSelector);

    function onScroll (element) {
      element.on('mousewheel DOMMouseScroll', function (event) {
          var oe = event.originalEvent;
          var delta = oe.wheelDelta || -oe.detail;

          this.scrollTop += ( delta < 0 ? 1 : -1 ) * 30;
          event.preventDefault();

          toggleTOCOverflowIndicators();
      });
    }

    function tocOverflowIndicator (indicator, action) {
      var $indicator = $(indicator);
      var opacity = action === 'show' ? 0.4 : 0;
      $indicator.velocity ?
        $indicator.velocity('stop').velocity({
          opacity: opacity
        }, { duration: 100 }) :
        $indicator.stop().animate({
          opacity: opacity
        }, 100);
    }

  });
</script>

<script type="text/javascript" id="sidebar.nav">
  $(document).ready(function () {
    var html = $('html');
    var TAB_ANIMATE_DURATION = 200;
    var hasVelocity = $.isFunction(html.velocity);

    $('.sidebar-nav li').on('click', function () {
      var item = $(this);
      var activeTabClassName = 'sidebar-nav-active';
      var activePanelClassName = 'sidebar-panel-active';
      if (item.hasClass(activeTabClassName)) {
        return;
      }

      var currentTarget = $('.' + activePanelClassName);
      var target = $('.' + item.data('target'));

      hasVelocity ?
        currentTarget.velocity('transition.slideUpOut', TAB_ANIMATE_DURATION, function () {
          target
            .velocity('stop')
            .velocity('transition.slideDownIn', TAB_ANIMATE_DURATION)
            .addClass(activePanelClassName);
        }) :
        currentTarget.animate({ opacity: 0 }, TAB_ANIMATE_DURATION, function () {
          currentTarget.hide();
          target
            .stop()
            .css({'opacity': 0, 'display': 'block'})
            .animate({ opacity: 1 }, TAB_ANIMATE_DURATION, function () {
              currentTarget.removeClass(activePanelClassName);
              target.addClass(activePanelClassName);
            });
        });

      item.siblings().removeClass(activeTabClassName);
      item.addClass(activeTabClassName);
    });

    $('.post-toc a').on('click', function (e) {
      e.preventDefault();
      var targetSelector = escapeSelector(this.getAttribute('href'));
      var offset = $(targetSelector).offset().top;
      hasVelocity ?
        html.velocity('stop').velocity('scroll', {
          offset: offset  + 'px',
          mobileHA: false
        }) :
        $('html, body').stop().animate({
          scrollTop: offset
        }, 500);
    });

    // Expand sidebar on post detail page by default, when post has a toc.
    var $tocContent = $('.post-toc-content');
    if (isDesktop() && CONFIG.sidebar === 'post') {
      if ($tocContent.length > 0 && $tocContent.html().trim().length > 0) {
        displaySidebar();
      }
    }
  });
</script>



  <script type="text/javascript">
    $(document).ready(function () {
      if (CONFIG.sidebar === 'always') {
        displaySidebar();
      }
      if (isMobile()) {
        FastClick.attach(document.body);
      }
    });
  </script>

  

  
  

  
  <script type="text/javascript" src="/js/lazyload.js"></script>
  <script type="text/javascript">
    $(function () {
      $("#posts").find('img').lazyload({
        placeholder: "/images/loading.gif",
        effect: "fadeIn"
      });
    });
  </script>
</body>
</html>
